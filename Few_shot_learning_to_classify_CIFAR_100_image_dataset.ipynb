{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Few shot learning to classify CIFAR 100 dataset"
      ],
      "metadata": {
        "id": "n_10VvERnfmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Create Few-Shot Learning support and query sets\n",
        "def create_few_shot_sets(x, y, n_classes, n_support, n_query):\n",
        "    classes = np.random.choice(np.unique(y), n_classes, replace=False)\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "    support_labels = []\n",
        "    query_labels = []\n",
        "\n",
        "    for i, cls in enumerate(classes):\n",
        "        cls_indices = np.where(y == cls)[0]\n",
        "        selected_indices = np.random.choice(cls_indices, n_support + n_query, replace=False)\n",
        "        support_set.append(x[selected_indices[:n_support]])\n",
        "        query_set.append(x[selected_indices[n_support:]])\n",
        "        support_labels.append(np.full((n_support,), i))\n",
        "        query_labels.append(np.full((n_query,), i))\n",
        "\n",
        "    support_set = np.concatenate(support_set, axis=0)\n",
        "    query_set = np.concatenate(query_set, axis=0)\n",
        "    support_labels = np.concatenate(support_labels, axis=0)\n",
        "    query_labels = np.concatenate(query_labels, axis=0)\n",
        "\n",
        "    return support_set, support_labels, query_set, query_labels\n",
        "\n",
        "# Few-Shot Learning hyperparameters\n",
        "n_classes = 5\n",
        "n_support = 5\n",
        "n_query = 15\n",
        "\n",
        "# Create Few-Shot Learning sets\n",
        "x_support, y_support, x_query, y_query = create_few_shot_sets(x_train, y_train, n_classes, n_support, n_query)\n",
        "\n",
        "# Define a custom CNN model with pooling and fully connected layers\n",
        "def create_custom_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the CNN model\n",
        "input_shape = x_train.shape[1:]\n",
        "num_classes = n_classes\n",
        "model = create_custom_cnn_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "train_generator = datagen.flow(x_support, y_support, batch_size=16)\n",
        "validation_data = (x_query, y_query)\n",
        "\n",
        "model.fit(train_generator, epochs=20, validation_data=validation_data)\n",
        "\n",
        "# Evaluate the model on query set\n",
        "loss, accuracy = model.evaluate(x_query, y_query)\n",
        "print(f'Few-Shot Learning Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp9Y6hMzo8o1",
        "outputId": "7d272d3c-13be-4116-f85a-c33439bcaa38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 553ms/step - loss: 1.6260 - accuracy: 0.1600 - val_loss: 1.5894 - val_accuracy: 0.3467\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.5738 - accuracy: 0.4800 - val_loss: 1.5643 - val_accuracy: 0.3867\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 1.5495 - accuracy: 0.5200 - val_loss: 1.5342 - val_accuracy: 0.3600\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 1.5020 - accuracy: 0.6000 - val_loss: 1.5087 - val_accuracy: 0.3600\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.4394 - accuracy: 0.6000 - val_loss: 1.4352 - val_accuracy: 0.4667\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 1.3466 - accuracy: 0.5200 - val_loss: 1.3687 - val_accuracy: 0.4400\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 1.2623 - accuracy: 0.5200 - val_loss: 1.3750 - val_accuracy: 0.3200\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 1.1477 - accuracy: 0.4800 - val_loss: 1.2835 - val_accuracy: 0.3867\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.0537 - accuracy: 0.5200 - val_loss: 1.2456 - val_accuracy: 0.4533\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 1.0114 - accuracy: 0.6000 - val_loss: 1.2495 - val_accuracy: 0.4400\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.1731 - accuracy: 0.4400 - val_loss: 1.2144 - val_accuracy: 0.4267\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.8932 - accuracy: 0.7200 - val_loss: 1.5532 - val_accuracy: 0.3733\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.0205 - accuracy: 0.5200 - val_loss: 1.4078 - val_accuracy: 0.3333\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.8422 - accuracy: 0.6000 - val_loss: 1.2844 - val_accuracy: 0.4533\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.0494 - accuracy: 0.4800 - val_loss: 1.2426 - val_accuracy: 0.4133\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.8256 - accuracy: 0.7600 - val_loss: 1.3743 - val_accuracy: 0.4533\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.9865 - accuracy: 0.6400 - val_loss: 1.6144 - val_accuracy: 0.4000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.8798 - accuracy: 0.6400 - val_loss: 1.1804 - val_accuracy: 0.5067\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.8258 - accuracy: 0.6800 - val_loss: 1.2079 - val_accuracy: 0.4000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.8026 - accuracy: 0.7600 - val_loss: 1.3088 - val_accuracy: 0.4533\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.3088 - accuracy: 0.4533\n",
            "Few-Shot Learning Accuracy: 0.4533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0M5TPHQpo9HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czFZwmCQZssq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuGMI7pSZto4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}